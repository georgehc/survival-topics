Loading SUPPORT_ARF_MOSF dataset...
  Total samples=4203
  Total features=55
Configuring experiments...
  Model=scholar_sagecox
  Params={'params': {'embedding_dim': [16, 32, 64], 'survival_loss_weight': [1.0, 100.0, 10000.0, 1000000.0], 'n_topics': [2, 3, 4, 5, 6], 'batch_size': [256], 'learning_rate': [0.01, 0.001], 'topic_l2_reg': [0.01, 0.1, 1.0, 10.0]}}
  Tuning scheme=grid
  Train/Test Split Repeats=1
  Training fraction=0.8
  Random seed=47
  >> Iter 0 best params:  {'batch_size': 256, 'embedding_dim': 64, 'learning_rate': 0.01, 'n_topics': 2, 'survival_loss_weight': 1000000.0, 'topic_l2_reg': 10.0, 'random_state': 2497306952}
  >> Iter 0 metrics:  {'concordance_antolini': 0.6326174259354382, 'concordance_median': nan, 'integrated_brier': nan, 'rmse': nan, 'mae': nan}
  >> Iter 0 bootstrapped : MEAN [0.63276453        nan        nan        nan        nan]
  >> Iter 0 bootstrapped : MEDIAN [0.63278849        nan        nan        nan        nan]
  >> Iter 0 bootstrapped : Q=0.025 [0.6073987       nan       nan       nan       nan]
  >> Iter 0 bootstrapped : Q=0.975 [0.65695336        nan        nan        nan        nan]
Finished!
